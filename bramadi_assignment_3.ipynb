{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a09a6d",
   "metadata": {},
   "source": [
    "## Analysis of Hate Crime data in United States\n",
    "The data ranges from years 2001 to 2020. \n",
    "I particularly chose this dataset for the following reasons:\n",
    "1. It contains various attributes to work with helping us have varius perspectives in the dataset\n",
    "2. Good analysis has the potential to provide impactful insights towards hate crime reduction procedures\n",
    "3. I understand that greater the size of the dataset more accurate is your analysis. Since this dataset has more than 100000 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f163bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hcrime_df = pd.read_csv(\"C:/Users/Nikitha/OneDrive/Documents/School/Assignments/Math_Methods_in_DA/hate_crime_dataset_3.csv\")\n",
    "hcrime_df = hcrime_df[['INCIDENT_ID','DATA_YEAR','PUB_AGENCY_NAME','PUB_AGENCY_UNIT','AGENCY_TYPE_NAME','STATE_NAME','POPULATION_GROUP_DESC','INCIDENT_DATE','TOTAL_OFFENDER_COUNT','ADULT_OFFENDER_COUNT','JUVENILE_OFFENDER_COUNT','OFFENDER_RACE','OFFENDER_ETHNICITY','OFFENSE_NAME','VICTIM_COUNT','LOCATION_NAME','BIAS_DESC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcrime_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219a61a",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "I have performed data wrangling at various places in this notebook.\n",
    "Performed the following the operations:\n",
    "1. POPULATION_GROUP_DESC -- get value after thru as a max population group--Retrive by extracting all the numbers in the text and getting a maximum of it\n",
    "2. INCIDENT_DATE parse it into proper date format inorder to retrieve month using an existing function\n",
    "3. LOCATION_NAME colunm spliting of multiple location if present and create a collect of location as a replacement. And later explode this collection to multiple it into different rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a780c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "total_incident_count = len(hcrime_df.INCIDENT_ID)\n",
    "latestyear_df = hcrime_df[hcrime_df.DATA_YEAR == 2020]\n",
    "total_incident_count_recent = len(latestyear_df)\n",
    "\n",
    "count_years = len(hcrime_df['DATA_YEAR'].unique())\n",
    "\n",
    "mean_incident_per_year = total_incident_count/count_years\n",
    "\n",
    "print(f'Total incidents reported from 2001 to 2020 = {total_incident_count}')\n",
    "print(f'Total incidents reported in 2020 = {total_incident_count_recent}')\n",
    "print(f'Mean incidents count for the recent ten years = {mean_incident_per_year:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_offender_count = sum(hcrime_df['TOTAL_OFFENDER_COUNT'])\n",
    "total_victim_count = sum(hcrime_df['VICTIM_COUNT'])\n",
    "\n",
    "print(f'Total offenders count from 2001 to 2020 has been = {total_offender_count}')\n",
    "print(f'Total victims count from 2001 to 2020 has been = {total_victim_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf3592",
   "metadata": {},
   "source": [
    "#### Measures of Central Tendency\n",
    "Calculation of mean, median and mode.\n",
    "The data I used to calculate the mean, median ,mode using the count of incidents each month over the years of 2001 to 2020\n",
    "\n",
    "Implemented the Data Wrangling Point 2 below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e19cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the string date to an actual date datatype\n",
    "hcrime_df['INCIDENT_DATE'] = pd.to_datetime(hcrime_df['INCIDENT_DATE'], format='%d-%b-%y')\n",
    "#Creating a new column by extracting month from a INCIDENT_DATE column\n",
    "hcrime_df['MONTH_OF_INCIDENT_DATE'] = pd.DatetimeIndex(hcrime_df['INCIDENT_DATE']).month\n",
    "#Grouping by Year and Month to calculate the count of incidents each month\n",
    "monthly_incident_counts = hcrime_df.groupby(['MONTH_OF_INCIDENT_DATE','DATA_YEAR']).size().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "import numpy as np\n",
    "\n",
    "print(f'stat.mean      = {stat.mean(monthly_incident_counts):.2f}')\n",
    "print(f'stat.median    = {stat.median(monthly_incident_counts):.2f}')\n",
    "print(f'stat.mode    = {stat.mode(monthly_incident_counts):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baffe7c",
   "metadata": {},
   "source": [
    "#### Measure of Variability\n",
    "Using the same dataset of incident count per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a789157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to calculate the range\n",
    "#Sorting the list of incident counts in ascending order\n",
    "sort_incident_counts = sorted(monthly_incident_counts)\n",
    "\n",
    "#Minimum value of the range\n",
    "min_incident_count_per_month = sort_incident_counts[0]\n",
    "print(f'minimum monthly incident count = {min_incident_count_per_month}')\n",
    "\n",
    "#Maximum value of the range\n",
    "max_incident_count_per_month = sort_incident_counts[-1]\n",
    "print(f'maximum monthly incident count = {max_incident_count_per_month}')\n",
    "\n",
    "#Calculation of variance\n",
    "print(f'stat.pvariance = {stat.pvariance(monthly_incident_counts):.2f}')\n",
    "\n",
    "#Calculate the standard deviation\n",
    "print(f'stat.pstdev    = {stat.pstdev(monthly_incident_counts):.2f}')\n",
    "\n",
    "#Interquartile range\n",
    "to_cal_qua = np.array(sort_incident_counts)\n",
    "q3, q1 = np.percentile(to_cal_qua,[75,25])\n",
    "inter_quartile_iqr = q3-q1\n",
    "\n",
    "print(f'Q1 is {q1:.2f}')\n",
    "print(f'Q3 is {q3:.2f}')\n",
    "print(f'Interquartile range = {inter_quartile_iqr:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9909b863",
   "metadata": {},
   "source": [
    "### Based on the bias evaluate the number of incidents over the year\n",
    "Based on the categorization information in https://www.fbi.gov/services/cjis/ucr/hate-crime i have grouped the column BIAS_DESC into 6 categories:\n",
    "1. Race/Ethnicity/Ancestry\n",
    "2. Religion -- not included below\n",
    "3. Sexual Orientation\n",
    "4. Disability\n",
    "5. Gender\n",
    "6. Gender Identity\n",
    "\n",
    "Result: Understoof that Race/Ethnicity/Ancestry is the most comman bias in the US\n",
    "\n",
    "This result justifies the most prevailing hate among the people living in the united states. Hence more programs to eradicate these difference can be conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f82c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to map the values in BIAS_DESC into the above list except Religion\n",
    "def categorize_bias(row):\n",
    "    if ('Anti-Female' in row['BIAS_DESC']) or ('Anti-Male' in row['BIAS_DESC']) :\n",
    "        return 'Gender'\n",
    "    elif ('Anti-Mental Disability' in row['BIAS_DESC']) or ('Anti-Physical Disability' in row['BIAS_DESC']) :\n",
    "        return 'Disability'\n",
    "    elif ('Anti-Bisexual' in row['BIAS_DESC']) or ('Anti-Gay (Male)' in row['BIAS_DESC']) or ('Anti-Heterosexual' in row['BIAS_DESC']) or ('Anti-Lesbian' in row['BIAS_DESC']) or ('Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group))' in row['BIAS_DESC']) :\n",
    "        return 'Sexual Orientation'\n",
    "    elif ('Anti-Transgender' in row['BIAS_DESC']) or ('Anti-Gender Non-Conforming' in row['BIAS_DESC']) :\n",
    "        return 'Gender Identity'\n",
    "    elif ('Anti-American Indian or Alaska Native' in row['BIAS_DESC']) or ('Anti-Arab' in row['BIAS_DESC']) or ('Anti-Asian' in row['BIAS_DESC']) or ('Anti-Black or African American' in row['BIAS_DESC']) or ('Anti-Hispanic or Latino' in row['BIAS_DESC']) or ('Anti-Multiple Races, Group' in row['BIAS_DESC']) or ('Anti-Native Hawaiian or Other Pacific Islander' in row['BIAS_DESC']) or ('Anti-Other Race/Ethnicity/Ancestry' in row['BIAS_DESC']) or ('Anti-White' in row['BIAS_DESC']) :\n",
    "        return 'Race/Ethnicity/Ancestry'\n",
    "    else :\n",
    "        return 'others or multiple bias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615e01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#To show the number incidents over the years based on the Bias\n",
    "bias_df = hcrime_df[['INCIDENT_ID','BIAS_DESC']]\n",
    "#Creating a new column GROUPED_BIAS which buckets the Biases into categories \n",
    "bias_df['GROUPED_BIAS'] = bias_df.apply(categorize_bias, axis=1)\n",
    "\n",
    "#Calculating the count of incidents based on the GROUPED_BIAS\n",
    "df = bias_df.groupby(bias_df['GROUPED_BIAS']).size()\n",
    "\n",
    "#PLotting Pie chart\n",
    "print('NUMBER OF INCIDENTS FROM 2001 to 2020 FOR VARIOUS BIASES')\n",
    "grp_bias = pd.DataFrame({'GROUPED_BIAS':df.index, 'incident_count':df.values})\n",
    "grp_bias.set_index('GROUPED_BIAS', inplace=True)\n",
    "grp_bias.plot.pie(y='incident_count',figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6621a9",
   "metadata": {},
   "source": [
    "### Crime incidents based on the max size of the population of a city or a county\n",
    "\n",
    "Here implemented the number 1 Data Wrangling point of extracting the maximum number from a given text in 'Cities from 250,000 thru 499,999' of a column POPULATION_GROUP_DESC\n",
    "\n",
    "Considering 250,000 is minimum polution range and 499,999 is the maximum population range.\n",
    "Here I have retrieved the maximum number from the text and considered as the population of that county or a city\n",
    "\n",
    "Result: A max population of 99,999 city or county has faced maximum incidents \n",
    "\n",
    "With this result we can target the cities and counties with the population range of 99,999 and perform further investigation of the cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2e08ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#Function extracting the numberical values from the text\n",
    "def getNumbers(str):\n",
    "    array = re.findall(r'[0-9]+', str)\n",
    "    return array\n",
    "#replacing the , in the text with no value\n",
    "hcrime_df['POPULATION_GROUP_DESC']=hcrime_df['POPULATION_GROUP_DESC'].replace(',','',regex=True)\n",
    "#Extracting number\n",
    "hcrime_df['POPULATION_NUMBERS']=hcrime_df['POPULATION_GROUP_DESC'].map(lambda x: str(getNumbers(x)))\n",
    "hcrime_df['POPULATION_NUMBERS']=hcrime_df['POPULATION_NUMBERS'].map(lambda x: str(re.findall(r\"(\\d+)']\",x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8245b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping the population to fetch the count of incidents in that type of population\n",
    "x = hcrime_df.groupby(['POPULATION_NUMBERS'])['TOTAL_OFFENDER_COUNT'].sum()\n",
    "x_df = pd.DataFrame({'population_numbers':x.index, 'count_of_incidents':x.values})\n",
    "#Creating a Bar plot\n",
    "print(\"CRIME INCIDENTS BASED ON THE MAX SIZE OF THE POPULATION OF A CITY OR A COUNTY\")\n",
    "x_df.sort_values(['count_of_incidents'], ascending=False).plot.bar(x = 'population_numbers', y = 'count_of_incidents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c8bac",
   "metadata": {},
   "source": [
    "### Group incidents and location correlation\n",
    "\n",
    "Considering a group of people is with 3 people or more I have choosed the cases where the offender counts are 3 or greater and tried to find the location where group offending most observed.\n",
    "\n",
    "Here Data Wrangling point 3 is executed of exploding the column\n",
    "\n",
    "RESULT:\n",
    "Highway/Road/Alley/Street/Sidewalk location is the most prone location for Group offending to occur\n",
    "\n",
    "From this result more security can be provided in this region in case of the prevalent group crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fbeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since few texts in LOCATION_NAME column have multiple locations separated by ;. This function would eliminate that and derive a list\n",
    "def split_multi_location(str):\n",
    "    if ';' in str:\n",
    "        return str.split(';')\n",
    "    else :\n",
    "        return str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of non-group incidents\n",
    "non_group_incident_cnt = len(hcrime_df[hcrime_df.TOTAL_OFFENDER_COUNT < 3])\n",
    "print(f'Total non group offending incident count from 2001 to 2020 has been = {non_group_incident_cnt}')\n",
    "\n",
    "#Count of group incidents\n",
    "group_incident_cnt = len(hcrime_df[hcrime_df.TOTAL_OFFENDER_COUNT >= 3])\n",
    "print(f'Total group offending incident count from 2001 to 2020 has been = {group_incident_cnt}')\n",
    "\n",
    "#filtering where offending happened in group\n",
    "grp_series = hcrime_df.loc[hcrime_df[\"TOTAL_OFFENDER_COUNT\"] >= 3,\"LOCATION_NAME\"]\n",
    "#Creating a dataframe\n",
    "grp_df = pd.DataFrame({'group_count':grp_series.index, 'location_name':grp_series.values})\n",
    "#In case of multiple locations\n",
    "grp_df['location_name'] = grp_df['location_name'].map(lambda x: split_multi_location(x))\n",
    "#Exploding the column\n",
    "m = grp_df.explode('location_name')\n",
    "\n",
    "location_series = m.groupby(m['location_name']).size()\n",
    "\n",
    "location_df = pd.DataFrame({'crime_location':location_series.index, 'group_incident_count':location_series.values})\n",
    "\n",
    "#In ascending order of incident count and getting the top 10\n",
    "location_df = location_df.sort_values(['group_incident_count'], ascending=False).head(10)\n",
    "location_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the pie chart to represent the same shown above\n",
    "print(\"SHOWCASE OF LOCATION CORRELATION TO GROUP HATE CRIME\")\n",
    "location_df.set_index('crime_location', inplace=True)\n",
    "location_df.plot.pie(y='group_incident_count',subplots=True ,figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3a07d5",
   "metadata": {},
   "source": [
    "### Juvinile in crime over the years in percentage measures\n",
    "\n",
    "Juvenile Hate crime has decreased from 2020 to 2019\n",
    "\n",
    "This outcome will just acknowledge that the juvenile crime have seen a better face from the year 2019 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc063e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_two_year = hcrime_df.loc[(hcrime_df['DATA_YEAR'] == 2020) | (hcrime_df['DATA_YEAR'] == 2019)]\n",
    "last_two_year = last_two_year.dropna()\n",
    "last_two_year = last_two_year[last_two_year['JUVENILE_OFFENDER_COUNT']!=0]\n",
    "juv_df = last_two_year[['DATA_YEAR','JUVENILE_OFFENDER_COUNT']]\n",
    "juv_df = juv_df.groupby(['DATA_YEAR'])['JUVENILE_OFFENDER_COUNT'].sum()\n",
    "juv_df.plot.bar(ylabel='Juvenile crime count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c7e25",
   "metadata": {},
   "source": [
    "#### Data Cleaning usage:\n",
    "    With Respect to the data cleaning, In this data I required to perform more of Data Wrangling than performing Data Cleaning. Data I chose was mostly neat and usable.\n",
    "#### My Approach to the analysis:\n",
    "    While finding the data I was looking data which is more understandable to human readability and having more attribute to experiment the analysis.\n",
    "    Crime data can be pretty common data across the internet. Here my approach was to retrieving something new which is not already available beforehand\n",
    "\n",
    "Outcomes are provided in markdown of each analysis done above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df700121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
